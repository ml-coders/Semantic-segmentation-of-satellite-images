{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Royal.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UCE2zGxWdYx0",
        "outputId": "b06275a7-1a08-4b8a-d687-f5d6ad8e0ad8"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "m_AWeem1Yjg0",
        "outputId": "aa7c3abb-d4d3-4ab7-a540-cbae60de23d8"
      },
      "source": [
        "%cd drive/\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5JGIV9nCY64Z",
        "outputId": "f58c0fff-205b-4e0f-a5ce-509f8438ab49"
      },
      "source": [
        "%cd MyDrive/\n",
        "!ls"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/drive/MyDrive\n",
            " Final_Project\t'Getting started.pdf'  'Untitled Jam.gjam'\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-UxjaCL2Y_qw",
        "outputId": "e7787120-4153-4c2e-a675-098397e4c728"
      },
      "source": [
        "%cd Final_Project/\n",
        "!ls"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/drive/.shortcut-targets-by-id/1Jt2ZZqfqgTMAMTeC9spu5aGpV6L3Kje3/Final_Project\n",
            " class_masks\t\t\t        LICENSE        Report.pdf\n",
            " compare_pred_to_gt\t\t        main_unet.py   requirements.txt\n",
            " Comparison_Test.pdf\t\t       'New folder'    test_outputs\n",
            " _config.yml\t\t\t        plots\t       test_unet.py\n",
            " confusion_matrices_train_and_val.txt   plots.png      train_predictions\n",
            " images_for_doc\t\t\t        PSPNet\t       unet.py\n",
            " Inter-IIT-CSRE\t\t\t        pywin-0.3.1    Untitled.ipynb\n",
            " iou.py\t\t\t\t        README.md\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RpfLkCAbd4pL",
        "outputId": "047325f2-7f6b-4546-92ff-e341b42245ae"
      },
      "source": [
        "!pip install -r requirements.txt"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: absl-py==0.10.0 in /usr/local/lib/python3.6/dist-packages (from -r requirements.txt (line 1)) (0.10.0)\n",
            "Requirement already satisfied: argon2-cffi==20.1.0 in /usr/local/lib/python3.6/dist-packages (from -r requirements.txt (line 2)) (20.1.0)\n",
            "Requirement already satisfied: astor==0.8.1 in /usr/local/lib/python3.6/dist-packages (from -r requirements.txt (line 3)) (0.8.1)\n",
            "Requirement already satisfied: async-generator==1.10 in /usr/local/lib/python3.6/dist-packages (from -r requirements.txt (line 4)) (1.10)\n",
            "Requirement already satisfied: attrs==20.2.0 in /usr/local/lib/python3.6/dist-packages (from -r requirements.txt (line 5)) (20.2.0)\n",
            "Requirement already satisfied: backcall==0.2.0 in /usr/local/lib/python3.6/dist-packages (from -r requirements.txt (line 6)) (0.2.0)\n",
            "Collecting bleach==3.1.5\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/9a/1e/7d6cb3b27cd2c490558349ca5d5cc05b390b017da1c704cac807ac8bd9fb/bleach-3.1.5-py2.py3-none-any.whl (151kB)\n",
            "\u001b[K     |████████████████████████████████| 153kB 10.3MB/s \n",
            "\u001b[?25hRequirement already satisfied: certifi==2020.6.20 in /usr/local/lib/python3.6/dist-packages (from -r requirements.txt (line 8)) (2020.6.20)\n",
            "Collecting cffi==1.14.2\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/82/7e/9cc46f072c9a414b5a6e08c5c2da5db3bff2601e69c4a6d4f6a34e6f9cfc/cffi-1.14.2-cp36-cp36m-manylinux1_x86_64.whl (400kB)\n",
            "\u001b[K     |████████████████████████████████| 409kB 9.5MB/s \n",
            "\u001b[?25hRequirement already satisfied: chardet==3.0.4 in /usr/local/lib/python3.6/dist-packages (from -r requirements.txt (line 10)) (3.0.4)\n",
            "Collecting colorama==0.4.3\n",
            "  Downloading https://files.pythonhosted.org/packages/c9/dc/45cdef1b4d119eb96316b3117e6d5708a08029992b2fee2c143c7a0a5cc5/colorama-0.4.3-py2.py3-none-any.whl\n",
            "Requirement already satisfied: cycler==0.10.0 in /usr/local/lib/python3.6/dist-packages (from -r requirements.txt (line 12)) (0.10.0)\n",
            "Requirement already satisfied: decorator==4.4.2 in /usr/local/lib/python3.6/dist-packages (from -r requirements.txt (line 13)) (4.4.2)\n",
            "Requirement already satisfied: defusedxml==0.6.0 in /usr/local/lib/python3.6/dist-packages (from -r requirements.txt (line 14)) (0.6.0)\n",
            "Requirement already satisfied: entrypoints==0.3 in /usr/local/lib/python3.6/dist-packages (from -r requirements.txt (line 15)) (0.3)\n",
            "Collecting gast==0.2.2\n",
            "  Downloading https://files.pythonhosted.org/packages/4e/35/11749bf99b2d4e3cceb4d55ca22590b0d7c2c62b9de38ac4a4a7f4687421/gast-0.2.2.tar.gz\n",
            "Requirement already satisfied: google-pasta==0.2.0 in /usr/local/lib/python3.6/dist-packages (from -r requirements.txt (line 17)) (0.2.0)\n",
            "Collecting grpcio==1.32.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/f0/00/b393f5d0e92b37592a41357ea3077010c95400c907f6b9af01f4f6abe140/grpcio-1.32.0-cp36-cp36m-manylinux2014_x86_64.whl (3.8MB)\n",
            "\u001b[K     |████████████████████████████████| 3.8MB 10.8MB/s \n",
            "\u001b[?25hRequirement already satisfied: h5py==2.10.0 in /usr/local/lib/python3.6/dist-packages (from -r requirements.txt (line 19)) (2.10.0)\n",
            "Requirement already satisfied: idna==2.10 in /usr/local/lib/python3.6/dist-packages (from -r requirements.txt (line 20)) (2.10)\n",
            "Collecting imageio==2.5.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/af/0a/943c965d372dae0b1f1482677d29030ab834351a61a9a632fd62f27f1523/imageio-2.5.0-py3-none-any.whl (3.3MB)\n",
            "\u001b[K     |████████████████████████████████| 3.3MB 42.1MB/s \n",
            "\u001b[?25hRequirement already satisfied: imgaug==0.2.9 in /usr/local/lib/python3.6/dist-packages (from -r requirements.txt (line 22)) (0.2.9)\n",
            "Collecting importlib-metadata==1.7.0\n",
            "  Downloading https://files.pythonhosted.org/packages/8e/58/cdea07eb51fc2b906db0968a94700866fc46249bdc75cac23f9d13168929/importlib_metadata-1.7.0-py2.py3-none-any.whl\n",
            "Collecting ipykernel==5.3.4\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/52/19/c2812690d8b340987eecd2cbc18549b1d130b94c5d97fcbe49f5f8710edf/ipykernel-5.3.4-py3-none-any.whl (120kB)\n",
            "\u001b[K     |████████████████████████████████| 122kB 51.0MB/s \n",
            "\u001b[?25hCollecting ipython==7.16.1\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/23/6a/210816c943c9aeeb29e4e18a298f14bf0e118fe222a23e13bfcc2d41b0a4/ipython-7.16.1-py3-none-any.whl (785kB)\n",
            "\u001b[K     |████████████████████████████████| 788kB 41.0MB/s \n",
            "\u001b[?25hRequirement already satisfied: ipython-genutils==0.2.0 in /usr/local/lib/python3.6/dist-packages (from -r requirements.txt (line 26)) (0.2.0)\n",
            "Requirement already satisfied: jedi==0.17.2 in /usr/local/lib/python3.6/dist-packages (from -r requirements.txt (line 27)) (0.17.2)\n",
            "Requirement already satisfied: Jinja2==2.11.2 in /usr/local/lib/python3.6/dist-packages (from -r requirements.txt (line 28)) (2.11.2)\n",
            "Collecting json5==0.9.5\n",
            "  Downloading https://files.pythonhosted.org/packages/2b/81/22bf51a5bc60dde18bb6164fd597f18ee683de8670e141364d9c432dd3cf/json5-0.9.5-py2.py3-none-any.whl\n",
            "Collecting jsonschema==3.2.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/c5/8f/51e89ce52a085483359217bc72cdbf6e75ee595d5b1d4b5ade40c7e018b8/jsonschema-3.2.0-py2.py3-none-any.whl (56kB)\n",
            "\u001b[K     |████████████████████████████████| 61kB 7.0MB/s \n",
            "\u001b[?25hCollecting jupyter-client==6.1.7\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/dc/41/9fa443d5ae8907dd8f7d12146cb0092dc053afd67b5b57e7e8786a328547/jupyter_client-6.1.7-py3-none-any.whl (108kB)\n",
            "\u001b[K     |████████████████████████████████| 112kB 52.0MB/s \n",
            "\u001b[?25hRequirement already satisfied: jupyter-core==4.6.3 in /usr/local/lib/python3.6/dist-packages (from -r requirements.txt (line 32)) (4.6.3)\n",
            "Collecting jupyterlab==2.2.7\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/82/bc/8ca618d6a18d49675ad39f544bcd6ad8a9f31a5784d059d7053c8ec3197b/jupyterlab-2.2.7-py3-none-any.whl (7.8MB)\n",
            "\u001b[K     |████████████████████████████████| 7.8MB 31.7MB/s \n",
            "\u001b[?25hCollecting jupyterlab-pygments==0.1.1\n",
            "  Downloading https://files.pythonhosted.org/packages/1f/4c/905faabb03f56ba92b1b9049436afead02bc09aae7e8f0d1107ebb46b151/jupyterlab_pygments-0.1.1-py2.py3-none-any.whl\n",
            "Collecting jupyterlab-server==1.2.0\n",
            "  Downloading https://files.pythonhosted.org/packages/b4/eb/560043dcd8376328f8b98869efed66ef68307278406ab99c7f63a34d4ae2/jupyterlab_server-1.2.0-py3-none-any.whl\n",
            "Requirement already satisfied: Keras==2.4.3 in /usr/local/lib/python3.6/dist-packages (from -r requirements.txt (line 36)) (2.4.3)\n",
            "Collecting Keras-Applications==1.0.8\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/71/e3/19762fdfc62877ae9102edf6342d71b28fbfd9dea3d2f96a882ce099b03f/Keras_Applications-1.0.8-py3-none-any.whl (50kB)\n",
            "\u001b[K     |████████████████████████████████| 51kB 6.1MB/s \n",
            "\u001b[?25hRequirement already satisfied: Keras-Preprocessing==1.1.2 in /usr/local/lib/python3.6/dist-packages (from -r requirements.txt (line 38)) (1.1.2)\n",
            "Collecting keras-segmentation==0.3.0\n",
            "  Downloading https://files.pythonhosted.org/packages/43/f0/b8def71a219c6a21f5201727082e846c560817712b3484e8f0c834c9c0e6/keras_segmentation-0.3.0.tar.gz\n",
            "Collecting kiwisolver==1.2.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/ae/23/147de658aabbf968324551ea22c0c13a00284c4ef49a77002e91f79657b7/kiwisolver-1.2.0-cp36-cp36m-manylinux1_x86_64.whl (88kB)\n",
            "\u001b[K     |████████████████████████████████| 92kB 8.5MB/s \n",
            "\u001b[?25hCollecting Markdown==3.2.2\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/a4/63/eaec2bd025ab48c754b55e8819af0f6a69e2b1e187611dd40cbbe101ee7f/Markdown-3.2.2-py3-none-any.whl (88kB)\n",
            "\u001b[K     |████████████████████████████████| 92kB 8.3MB/s \n",
            "\u001b[?25hRequirement already satisfied: MarkupSafe==1.1.1 in /usr/local/lib/python3.6/dist-packages (from -r requirements.txt (line 42)) (1.1.1)\n",
            "Collecting matplotlib==3.3.1\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/96/a7/b6fa244fd8a8814ef9408c8a5a7e4ed0340e232a6f0ce2046b42e50672c0/matplotlib-3.3.1-cp36-cp36m-manylinux1_x86_64.whl (11.6MB)\n",
            "\u001b[K     |████████████████████████████████| 11.6MB 23.2MB/s \n",
            "\u001b[?25hRequirement already satisfied: mistune==0.8.4 in /usr/local/lib/python3.6/dist-packages (from -r requirements.txt (line 44)) (0.8.4)\n",
            "Collecting nbclient==0.5.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/c3/c0/b8802a7cd2bb7a81a64a580eb65047d2931fd9fea8c038ff3ada2a6bd0ae/nbclient-0.5.0-py3-none-any.whl (65kB)\n",
            "\u001b[K     |████████████████████████████████| 71kB 8.0MB/s \n",
            "\u001b[?25hCollecting nbconvert==6.0.2\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/91/99/5fc216371c68cf2f60cfe585b6ec91ac6934698b562226b22a4d99b9eb62/nbconvert-6.0.2-py3-none-any.whl (504kB)\n",
            "\u001b[K     |████████████████████████████████| 512kB 44.5MB/s \n",
            "\u001b[?25hCollecting nbformat==5.0.7\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/4d/d1/b568bd35f95321f152f594b3647cd080e96d3347843ff2fa34dce871b8bf/nbformat-5.0.7-py3-none-any.whl (170kB)\n",
            "\u001b[K     |████████████████████████████████| 174kB 50.6MB/s \n",
            "\u001b[?25hCollecting nest-asyncio==1.4.0\n",
            "  Downloading https://files.pythonhosted.org/packages/a0/44/f2983c5be9803b08f89380229997e92c4bdd7a4a510ccee565b599d1bdc8/nest_asyncio-1.4.0-py3-none-any.whl\n",
            "Requirement already satisfied: networkx==2.5 in /usr/local/lib/python3.6/dist-packages (from -r requirements.txt (line 49)) (2.5)\n",
            "Collecting notebook==6.1.4\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/cc/00/0db4005f8410c0c6c598d6beecd650846e00955a3bf800ea09872a9009f1/notebook-6.1.4-py3-none-any.whl (9.5MB)\n",
            "\u001b[K     |████████████████████████████████| 9.5MB 2.0MB/s \n",
            "\u001b[?25hCollecting numpy==1.19.2\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/63/97/af8a92864a04bfa48f1b5c9b1f8bf2ccb2847f24530026f26dd223de4ca0/numpy-1.19.2-cp36-cp36m-manylinux2010_x86_64.whl (14.5MB)\n",
            "\u001b[K     |████████████████████████████████| 14.5MB 40.3MB/s \n",
            "\u001b[?25hCollecting opencv-python==4.4.0.42\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/46/16/e49e5abd27d988e687634f58b0aa329fe737b686101cda48cd878f77429d/opencv_python-4.4.0.42-cp36-cp36m-manylinux2014_x86_64.whl (49.4MB)\n",
            "\u001b[K     |████████████████████████████████| 49.4MB 79kB/s \n",
            "\u001b[?25hRequirement already satisfied: opt-einsum==3.3.0 in /usr/local/lib/python3.6/dist-packages (from -r requirements.txt (line 53)) (3.3.0)\n",
            "Requirement already satisfied: packaging==20.4 in /usr/local/lib/python3.6/dist-packages (from -r requirements.txt (line 54)) (20.4)\n",
            "Collecting pandocfilters==1.4.2\n",
            "  Downloading https://files.pythonhosted.org/packages/4c/ea/236e2584af67bb6df960832731a6e5325fd4441de001767da328c33368ce/pandocfilters-1.4.2.tar.gz\n",
            "Requirement already satisfied: parso==0.7.1 in /usr/local/lib/python3.6/dist-packages (from -r requirements.txt (line 56)) (0.7.1)\n",
            "Requirement already satisfied: pickleshare==0.7.5 in /usr/local/lib/python3.6/dist-packages (from -r requirements.txt (line 57)) (0.7.5)\n",
            "Collecting Pillow==7.2.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/30/bf/92385b4262178ca22b34f82e0e09c2922eb351fe39f3cc7b8ba9ea555b41/Pillow-7.2.0-cp36-cp36m-manylinux1_x86_64.whl (2.2MB)\n",
            "\u001b[K     |████████████████████████████████| 2.2MB 36.0MB/s \n",
            "\u001b[?25hRequirement already satisfied: prometheus-client==0.8.0 in /usr/local/lib/python3.6/dist-packages (from -r requirements.txt (line 59)) (0.8.0)\n",
            "Collecting prompt-toolkit==3.0.7\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/2b/c1/53ac685833200eb77ef485c2220dac5bfc255418e660790a9eb5cf3abf25/prompt_toolkit-3.0.7-py3-none-any.whl (355kB)\n",
            "\u001b[K     |████████████████████████████████| 358kB 36.5MB/s \n",
            "\u001b[?25hCollecting protobuf==3.13.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/30/79/510974552cebff2ba04038544799450defe75e96ea5f1675dbf72cc8744f/protobuf-3.13.0-cp36-cp36m-manylinux1_x86_64.whl (1.3MB)\n",
            "\u001b[K     |████████████████████████████████| 1.3MB 41.9MB/s \n",
            "\u001b[?25hRequirement already satisfied: pycparser==2.20 in /usr/local/lib/python3.6/dist-packages (from -r requirements.txt (line 62)) (2.20)\n",
            "Collecting Pygments==2.7.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/5e/ac/cc00398eccce66515a8acac52afa3e51bbe9a8080e9f232aa91cbb041856/Pygments-2.7.0-py3-none-any.whl (950kB)\n",
            "\u001b[K     |████████████████████████████████| 952kB 35.0MB/s \n",
            "\u001b[?25hRequirement already satisfied: pyparsing==2.4.7 in /usr/local/lib/python3.6/dist-packages (from -r requirements.txt (line 64)) (2.4.7)\n",
            "Requirement already satisfied: pyrsistent==0.17.3 in /usr/local/lib/python3.6/dist-packages (from -r requirements.txt (line 65)) (0.17.3)\n",
            "Requirement already satisfied: python-dateutil==2.8.1 in /usr/local/lib/python3.6/dist-packages (from -r requirements.txt (line 66)) (2.8.1)\n",
            "Requirement already satisfied: PyWavelets==1.1.1 in /usr/local/lib/python3.6/dist-packages (from -r requirements.txt (line 67)) (1.1.1)\n",
            "\u001b[31mERROR: Could not find a version that satisfies the requirement pywin32==228 (from -r requirements.txt (line 68)) (from versions: none)\u001b[0m\n",
            "\u001b[31mERROR: No matching distribution found for pywin32==228 (from -r requirements.txt (line 68))\u001b[0m\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zYaHh6N-ZSe3",
        "outputId": "e5bcba7b-3e6f-403f-cf4e-23ea6cb58d00"
      },
      "source": [
        "!pip install libtiff"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: libtiff in /usr/local/lib/python3.6/dist-packages (0.4.2)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "s1TCsWZtcSmw",
        "outputId": "c3bc0877-ea07-431c-882c-594def1d92a0"
      },
      "source": [
        "! lsb_release -a"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "No LSB modules are available.\n",
            "Distributor ID:\tUbuntu\n",
            "Description:\tUbuntu 18.04.5 LTS\n",
            "Release:\t18.04\n",
            "Codename:\tbionic\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dcJoxbj5ZYjs",
        "outputId": "f0edc756-ae7c-4754-8f56-d7353b5a37fc"
      },
      "source": [
        "!pip install scipy==1.5.2"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting scipy==1.5.2\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/2b/a8/f4c66eb529bb252d50e83dbf2909c6502e2f857550f22571ed8556f62d95/scipy-1.5.2-cp36-cp36m-manylinux1_x86_64.whl (25.9MB)\n",
            "\u001b[K     |████████████████████████████████| 25.9MB 149kB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.14.5 in /usr/local/lib/python3.6/dist-packages (from scipy==1.5.2) (1.18.5)\n",
            "\u001b[31mERROR: tensorflow 2.3.0 has requirement scipy==1.4.1, but you'll have scipy 1.5.2 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: albumentations 0.1.12 has requirement imgaug<0.2.7,>=0.2.5, but you'll have imgaug 0.2.9 which is incompatible.\u001b[0m\n",
            "Installing collected packages: scipy\n",
            "  Found existing installation: scipy 1.4.1\n",
            "    Uninstalling scipy-1.4.1:\n",
            "      Successfully uninstalled scipy-1.4.1\n",
            "Successfully installed scipy-1.5.2\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 309
        },
        "id": "XSMKb-D4Zymj",
        "outputId": "20185b23-edbc-4148-e2bb-bb436b070d95"
      },
      "source": [
        "!pip install numpy==1.19.2"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting numpy==1.19.2\n",
            "  Using cached https://files.pythonhosted.org/packages/63/97/af8a92864a04bfa48f1b5c9b1f8bf2ccb2847f24530026f26dd223de4ca0/numpy-1.19.2-cp36-cp36m-manylinux2010_x86_64.whl\n",
            "\u001b[31mERROR: tensorflow 2.3.0 has requirement numpy<1.19.0,>=1.16.0, but you'll have numpy 1.19.2 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: tensorflow 2.3.0 has requirement scipy==1.4.1, but you'll have scipy 1.5.2 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: datascience 0.10.6 has requirement folium==0.2.1, but you'll have folium 0.8.3 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: albumentations 0.1.12 has requirement imgaug<0.2.7,>=0.2.5, but you'll have imgaug 0.2.9 which is incompatible.\u001b[0m\n",
            "Installing collected packages: numpy\n",
            "  Found existing installation: numpy 1.18.5\n",
            "    Uninstalling numpy-1.18.5:\n",
            "      Successfully uninstalled numpy-1.18.5\n",
            "Successfully installed numpy-1.19.2\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "numpy"
                ]
              }
            }
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TZH8d6i9aIvW",
        "outputId": "83696cac-ba14-4b9d-be88-9b8cc12bff65"
      },
      "source": [
        "!pip install scipy==1.1.0"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting scipy==1.1.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/a8/0b/f163da98d3a01b3e0ef1cab8dd2123c34aee2bafbb1c5bffa354cc8a1730/scipy-1.1.0-cp36-cp36m-manylinux1_x86_64.whl (31.2MB)\n",
            "\u001b[K     |████████████████████████████████| 31.2MB 103kB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.8.2 in /usr/local/lib/python3.6/dist-packages (from scipy==1.1.0) (1.19.2)\n",
            "\u001b[31mERROR: umap-learn 0.4.6 has requirement scipy>=1.3.1, but you'll have scipy 1.1.0 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: tensorflow 2.3.0 has requirement numpy<1.19.0,>=1.16.0, but you'll have numpy 1.19.2 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: tensorflow 2.3.0 has requirement scipy==1.4.1, but you'll have scipy 1.1.0 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: plotnine 0.6.0 has requirement scipy>=1.2.0, but you'll have scipy 1.1.0 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: albumentations 0.1.12 has requirement imgaug<0.2.7,>=0.2.5, but you'll have imgaug 0.2.9 which is incompatible.\u001b[0m\n",
            "Installing collected packages: scipy\n",
            "  Found existing installation: scipy 1.5.2\n",
            "    Uninstalling scipy-1.5.2:\n",
            "      Successfully uninstalled scipy-1.5.2\n",
            "Successfully installed scipy-1.1.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "REHptoyUit23"
      },
      "source": [
        "import PIL\n",
        "from PIL import Image\n",
        "import matplotlib.pyplot as plt\n",
        "from libtiff import TIFF\n",
        "from libtiff import TIFFfile, TIFFimage\n",
        "from scipy.misc import imresize\n",
        "import numpy as np\n",
        "import math\n",
        "import glob\n",
        "import cv2\n",
        "import os\n",
        "import skimage.io as io\n",
        "import skimage.transform as trans\n",
        "from keras.models import *\n",
        "from keras.layers import *\n",
        "from keras.optimizers import *\n",
        "from keras.callbacks import ModelCheckpoint, LearningRateScheduler\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "from keras import backend as keras"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y302Ub51kL4Q"
      },
      "source": [
        "def iou(y_true, y_pred, smooth = 100):\n",
        "    intersection = K.sum(K.abs(y_true * y_pred), axis=-1)\n",
        "    union = K.sum(y_true,-1) + K.sum(y_pred,-1) - intersection\n",
        "    #sum_ = K.sum(K.abs(y_true) + K.abs(y_pred), axis=-1)\n",
        "    iou_acc = (intersection + smooth) / (union + smooth)\n",
        "    return iou_acc"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nVad6Y3ekeRM"
      },
      "source": [
        "def as_keras_metric(method):\n",
        "    import functools\n",
        "    from keras import backend as K\n",
        "    import tensorflow as tf\n",
        "    @functools.wraps(method)\n",
        "    def wrapper(self, args, **kwargs):\n",
        "        \"\"\" Wrapper for turning tensorflow metrics into keras metrics \"\"\"\n",
        "        value, update_op = method(self, args, **kwargs)\n",
        "        K.get_session().run(tf.local_variables_initializer())\n",
        "        with tf.control_dependencies([update_op]):\n",
        "            value = tf.identity(value)\n",
        "        return value\n",
        "    return wrapper\n",
        "\n",
        "def tf_mean_iou(y_true, y_pred, num_classes=8):\n",
        "    return tf.metrics.mean_iou(y_true, y_pred, num_classes)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t3OoXlj6knBM"
      },
      "source": [
        "mean_iou = as_keras_metric(tf_mean_iou)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2uUSDIMWkqhi"
      },
      "source": [
        "import re\n",
        "numbers = re.compile(r'(\\d+)')\n",
        "def numericalSort(value):\n",
        "    parts = numbers.split(value)\n",
        "    parts[1::2] = map(int, parts[1::2])\n",
        "    return parts\n",
        "\n",
        "# List of file names of actual Satellite images for traininig \n",
        "filelist_trainx = sorted(glob.glob('Inter-IIT-CSRE/The-Eye-in-the-Sky-dataset/sat/*.tif'), key=numericalSort)\n",
        "# List of file names of classified images for traininig \n",
        "filelist_trainy = sorted(glob.glob('Inter-IIT-CSRE/The-Eye-in-the-Sky-dataset/gt/*.tif'), key=numericalSort)\n",
        "\n",
        "# List of file names of actual Satellite images for testing \n",
        "filelist_testx = sorted(glob.glob('Inter-IIT-CSRE/The-Eye-in-the-Sky-test-data/sat_test/*.tif'), key=numericalSort)\n",
        "                                        \n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6D1sJlhNkvkD"
      },
      "source": [
        "def resize(img, stride, n_h, n_w):\n",
        "    #h,l,_ = img.shape\n",
        "    ne_h = (n_h*stride) + stride\n",
        "    ne_w = (n_w*stride) + stride\n",
        "    \n",
        "    img_resized = imresize(img, (ne_h,ne_w))\n",
        "    return img_resized\n",
        "\n",
        "# Padding at the bottem and at the left of images to be able to crop them into 128*128 images for training\n",
        "\n",
        "def padding(img, w, h, c, crop_size, stride, n_h, n_w):\n",
        "    \n",
        "    w_extra = w - ((n_w-1)*stride)\n",
        "    w_toadd = crop_size - w_extra\n",
        "    \n",
        "    h_extra = h - ((n_h-1)*stride)\n",
        "    h_toadd = crop_size - h_extra\n",
        "    \n",
        "    img_pad = np.zeros(((h+h_toadd), (w+w_toadd), c))\n",
        "    #img_pad[:h, :w,:] = img\n",
        "    #img_pad = img_pad+img\n",
        "    img_pad = np.pad(img, [(0, h_toadd), (0, w_toadd), (0,0)], mode='constant')\n",
        "    \n",
        "    return img_pad\n",
        "    \n",
        "\n",
        "\n",
        "# Adding pixels to make the image with shape in multiples of stride\n",
        "\n",
        "def add_pixals(img, h, w, c, n_h, n_w, crop_size, stride):\n",
        "        \n",
        "    w_extra = w - ((n_w-1)*stride)\n",
        "    w_toadd = crop_size - w_extra\n",
        "\n",
        "    h_extra = h - ((n_h-1)*stride)\n",
        "    h_toadd = crop_size - h_extra\n",
        "\n",
        "    img_add = np.zeros(((h+h_toadd), (w+w_toadd), c))\n",
        "        \n",
        "    img_add[:h, :w,:] = img\n",
        "    img_add[h:, :w,:] = img[:h_toadd,:, :]\n",
        "    img_add[:h,w:,:] = img[:,:w_toadd,:]\n",
        "    img_add[h:,w:,:] = img[h-h_toadd:h,w-w_toadd:w,:]\n",
        "            \n",
        "    return img_add    \n",
        "\n",
        "\n",
        "\n",
        "# Adding pixels to make the image with shape in multiples of stride\n",
        "\n",
        "def add_pixals(img, h, w, c, n_h, n_w, crop_size, stride):\n",
        "    \n",
        "    w_extra = w - ((n_w-1)*stride)\n",
        "    w_toadd = crop_size - w_extra\n",
        "    \n",
        "    h_extra = h - ((n_h-1)*stride)\n",
        "    h_toadd = crop_size - h_extra\n",
        "    \n",
        "    img_add = np.zeros(((h+h_toadd), (w+w_toadd), c))\n",
        "    \n",
        "    img_add[:h, :w,:] = img\n",
        "    img_add[h:, :w,:] = img[:h_toadd,:, :]\n",
        "    img_add[:h,w:,:] = img[:,:w_toadd,:]\n",
        "    img_add[h:,w:,:] = img[h-h_toadd:h,w-w_toadd:w,:]\n",
        "    \n",
        "    return img_add    \n",
        "\n",
        "\n",
        "# Slicing the image into crop_size*crop_size crops with a stride of crop_size/2 and makking list out of them\n",
        "\n",
        "def crops(a, crop_size = 128):\n",
        "    \n",
        "    stride = int(crop_size/2)\n",
        "    # stride = 32\n",
        "\n",
        "    croped_images = []\n",
        "    h, w, c = a.shape\n",
        "    \n",
        "    n_h = int(int(h/stride))\n",
        "    n_w = int(int(w/stride))\n",
        "    \n",
        "    # Padding using the padding function we wrote\n",
        "    a = padding(a, w, h, c, crop_size, stride, n_h, n_w)\n",
        "    \n",
        "    # Resizing as required\n",
        "    ##a = resize(a, stride, n_h, n_w)\n",
        "    \n",
        "    # Adding pixals as required\n",
        "    #a = add_pixals(a, h, w, c, n_h, n_w, crop_size, stride)\n",
        "    \n",
        "    # Slicing the image into 128*128 crops with a stride of 64\n",
        "    for i in range(n_h-1):\n",
        "        for j in range(n_w-1):\n",
        "            crop_x = a[(i*stride):((i*stride)+crop_size), (j*stride):((j*stride)+crop_size), :]\n",
        "            croped_images.append(crop_x)\n",
        "    return croped_images\n",
        "\n",
        "\n",
        "# Another type of cropping\n",
        "\n",
        "def new_crops(img, crop_size = 512):\n",
        "    stride = crop_size \n",
        "    \n",
        "    croped_images = []\n",
        "    h, w, c = img.shape\n",
        "    \n",
        "    n_h = math.ceil(h/stride)\n",
        "    n_w = math.ceil(w/stride)\n",
        "    \n",
        "    for i in range(n_h):\n",
        "        \n",
        "        if (h - i*crop_size) >= crop_size:\n",
        "            stride = crop_size\n",
        "        elif (h - i*crop_size) <= crop_size:\n",
        "            stride = (crop_size - (w - i*crop_size))\n",
        "        for j in range(n_w):\n",
        "            if (w - i*crop_size) >= crop_size:\n",
        "                stride = crop_size\n",
        "            elif (w - i*crop_size) <= crop_size:\n",
        "                stride = (crop_size - (w - i*crop_size))\n",
        "                \n",
        "            crop_x = img[(i*stride):((i*stride)+crop_size), (j*stride):((j*stride)+crop_size), :]\n",
        "            croped_images.append(crop_x)\n",
        "    return croped_images\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ocGSG80Zk286"
      },
      "source": [
        "trainx_list = []\n",
        "\n",
        "for fname in filelist_trainx[:13]:\n",
        "    \n",
        "    # Reading the image\n",
        "    tif = TIFF.open(fname)\n",
        "    image = tif.read_image()\n",
        "    \n",
        "    # Padding as required and cropping\n",
        "    crops_list = crops(image)\n",
        "    #print(len(crops_list))\n",
        "    trainx_list = trainx_list + crops_list\n",
        "    \n",
        "# Array of all the cropped Training sat Images    \n",
        "trainx = np.asarray(trainx_list)\n",
        "\n",
        "\n",
        "# Reading, padding, cropping and making array of all the cropped images of all the trainig gt images\n",
        "trainy_list = []\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "w2Sg6YgLm0KR",
        "outputId": "3641e442-4769-47d8-8372-dd148cdcee51"
      },
      "source": [
        "for fname in filelist_trainy[:13]:\n",
        "    print(fname)\n",
        "    # Reading the image\n",
        "    tif = TIFF.open(fname)\n",
        "    image = tif.read_image()\n",
        "    # # Padding as required and cropping\n",
        "    image = trans.resize(image,(1024,1024,3))\n",
        "    crops_list =crops(image)\n",
        "    \n",
        "    trainy_list = trainy_list + crops_list\n",
        "    \n",
        "# Array of all the cropped Training gt Images    \n",
        "trainy = np.asarray(trainy_list)\n",
        "\n",
        "\n",
        "# Reading, padding, cropping and making array of all the cropped images of all the testing sat images\n",
        "testx_list = []"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Inter-IIT-CSRE/The-Eye-in-the-Sky-dataset/gt/JAX_004_006_CLS.tif\n",
            "Inter-IIT-CSRE/The-Eye-in-the-Sky-dataset/gt/JAX_004_007_CLS.tif\n",
            "Inter-IIT-CSRE/The-Eye-in-the-Sky-dataset/gt/JAX_004_009_CLS.tif\n",
            "Inter-IIT-CSRE/The-Eye-in-the-Sky-dataset/gt/JAX_004_010_CLS.tif\n",
            "Inter-IIT-CSRE/The-Eye-in-the-Sky-dataset/gt/JAX_004_012_CLS.tif\n",
            "Inter-IIT-CSRE/The-Eye-in-the-Sky-dataset/gt/JAX_004_013_CLS.tif\n",
            "Inter-IIT-CSRE/The-Eye-in-the-Sky-dataset/gt/JAX_004_014_CLS.tif\n",
            "Inter-IIT-CSRE/The-Eye-in-the-Sky-dataset/gt/JAX_004_015_CLS.tif\n",
            "Inter-IIT-CSRE/The-Eye-in-the-Sky-dataset/gt/JAX_004_016_CLS.tif\n",
            "Inter-IIT-CSRE/The-Eye-in-the-Sky-dataset/gt/JAX_004_019_CLS.tif\n",
            "Inter-IIT-CSRE/The-Eye-in-the-Sky-dataset/gt/JAX_004_022_CLS.tif\n",
            "Inter-IIT-CSRE/The-Eye-in-the-Sky-dataset/gt/JAX_017_001_CLS.tif\n",
            "Inter-IIT-CSRE/The-Eye-in-the-Sky-dataset/gt/JAX_017_002_CLS.tif\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "17WogOqCp_zg"
      },
      "source": [
        "tif = TIFF.open(filelist_trainx[13])\n",
        "image = tif.read_image()\n",
        "    \n",
        "# Padding as required and cropping\n",
        "crops_list = crops(image)\n",
        "    \n",
        "testx_list = testx_list + crops_list\n",
        "    \n",
        "# Array of all the cropped Testing sat Images  \n",
        "testx = np.asarray(testx_list)\n",
        "\n",
        "\n",
        "# Reading, padding, cropping and making array of all the cropped images of all the testing sat images\n",
        "testy_list = []\n",
        "\n",
        "#for fname in filelist_trainx[13]:\n",
        "    \n",
        "# Reading the image\n",
        "tif = TIFF.open(filelist_trainy[13])\n",
        "image = tif.read_image()\n",
        "image = trans.resize(image,(1024,1024,3));\n",
        "# Padding as required and cropping\n",
        "crops_list = crops(image)\n",
        "    \n",
        "testy_list = testy_list + crops_list\n",
        "    \n",
        "# Array of all the cropped Testing sat Images  \n",
        "testy = np.asarray(testy_list)\n",
        "\n",
        "# Making array of all the training sat images as it is without any cropping\n",
        "\n",
        "xtrain_list = []\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7nE-vOopqPNO"
      },
      "source": [
        "for fname in filelist_trainx:\n",
        "    \n",
        "    # Reading the image\n",
        "    tif = TIFF.open(fname)\n",
        "    image = tif.read_image()\n",
        "    \n",
        "    crop_size = 128\n",
        "    \n",
        "    stride = 64\n",
        "    \n",
        "    h, w, c = image.shape\n",
        "    \n",
        "    n_h = int(int(h/stride))\n",
        "    n_w = int(int(w/stride))\n",
        "    \n",
        "    \n",
        "    image = padding(image, w, h, c, crop_size, stride, n_h, n_w)\n",
        "    \n",
        "    xtrain_list.append(image)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c7ZVQUOvqxSX"
      },
      "source": [
        "x_train = np.asarray(xtrain_list)\n",
        "tif = TIFF.open('Inter-IIT-CSRE/The-Eye-in-the-Sky-dataset/sat/JAX_028_011_RGB.tif')\n",
        "image = tif.read_image()\n",
        "crop_size = 128\n",
        "    \n",
        "stride = 64\n",
        "h, w, c = image.shape\n",
        "    \n",
        "n_h = int(int(h/stride))\n",
        "n_w = int(int(w/stride))\n",
        "    \n",
        "    \n",
        "image = padding(image, w, h, c, crop_size, stride, n_h, n_w)\n",
        "x_train = image\n",
        "# Making array of all the training gt images as it is without any cropping\n",
        "\n",
        "ytrain_list = []\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-jmLqINnq7MC"
      },
      "source": [
        "for fname in filelist_trainy:\n",
        "    \n",
        "    # Reading the image\n",
        "    tif = TIFF.open(fname)\n",
        "    image = tif.read_image()\n",
        "    \n",
        "    crop_size = 128\n",
        "    \n",
        "    stride = 64\n",
        "    image = trans.resize(image,(1024,1024,3));\n",
        "    h, w, c = image.shape\n",
        "    \n",
        "    n_h = int(int(h/stride))\n",
        "    n_w = int(int(w/stride))\n",
        "    \n",
        "    \n",
        "    image = padding(image, w, h, c, crop_size, stride, n_h, n_w)\n",
        "    \n",
        "    ytrain_list.append(image)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4Q0ykKPxriOI"
      },
      "source": [
        "y_train = np.asarray(ytrain_list)\n",
        "\n",
        "\n",
        "tif = TIFF.open('Inter-IIT-CSRE/The-Eye-in-the-Sky-dataset/gt/JAX_028_011_CLS.tif')\n",
        "image = tif.read_image()\n",
        "crop_size = 128\n",
        "    \n",
        "stride = 64\n",
        "image = trans.resize(image,(1024,1024,3));\n",
        "h, w, c = image.shape\n",
        "    \n",
        "n_h = int(int(h/stride))\n",
        "n_w = int(int(w/stride))\n",
        "    \n",
        "    \n",
        "image = padding(image, w, h, c, crop_size, stride, n_h, n_w)\n",
        "y_train = image"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N86m8gV5sIwU"
      },
      "source": [
        "def unet(shape = (1024,1024,3)):\n",
        "    \n",
        "    # Left side of the U-Net\n",
        "    inputs = Input(shape)\n",
        "    in_shape = inputs.shape\n",
        "    print(in_shape)\n",
        "    conv1 = Conv2D(64, 3, activation = 'relu', padding = 'same', kernel_initializer = 'random_normal')(inputs)\n",
        "    conv1 = Conv2D(64, 3, activation = 'relu', padding = 'same', kernel_initializer = 'random_normal')(conv1)\n",
        "    conv1 = BatchNormalization()(conv1)\n",
        "    pool1 = MaxPooling2D(pool_size=(2, 2))(conv1)\n",
        "    conv2 = Conv2D(128, 3, activation = 'relu', padding = 'same', kernel_initializer = 'random_normal')(pool1)\n",
        "    conv2 = Conv2D(128, 3, activation = 'relu', padding = 'same', kernel_initializer = 'random_normal')(conv2)\n",
        "    conv2 = BatchNormalization()(conv2)\n",
        "    pool2 = MaxPooling2D(pool_size=(2, 2))(conv2)\n",
        "    conv3 = Conv2D(256, 3, activation = 'relu', padding = 'same', kernel_initializer = 'random_normal')(pool2)\n",
        "    conv3 = Conv2D(256, 3, activation = 'relu', padding = 'same', kernel_initializer = 'random_normal')(conv3)\n",
        "    conv3 = BatchNormalization()(conv3)\n",
        "    pool3 = MaxPooling2D(pool_size=(2, 2))(conv3)\n",
        "    conv4 = Conv2D(512, 3, activation = 'relu', padding = 'same', kernel_initializer = 'random_normal')(pool3)\n",
        "    conv4 = Conv2D(512, 3, activation = 'relu', padding = 'same', kernel_initializer = 'random_normal')(conv4)\n",
        "    conv4 = BatchNormalization()(conv4)\n",
        "    drop4 = Dropout(0.5)(conv4)\n",
        "    pool4 = MaxPooling2D(pool_size=(2, 2))(drop4)\n",
        "    \n",
        "    # Bottom of the U-Net\n",
        "    conv5 = Conv2D(1024, 3, activation = 'relu', padding = 'same', kernel_initializer = 'random_normal')(pool4)\n",
        "    conv5 = Conv2D(1024, 3, activation = 'relu', padding = 'same', kernel_initializer = 'random_normal')(conv5)\n",
        "    conv5 = BatchNormalization()(conv5)\n",
        "    drop5 = Dropout(0.5)(conv5)\n",
        "    \n",
        "    # Upsampling Starts, right side of the U-Net\n",
        "    up6 = Conv2D(512, 2, activation = 'relu', padding = 'same', kernel_initializer = 'random_normal')(UpSampling2D(size = (2,2))(drop5))\n",
        "    merge6 = concatenate([drop4,up6], axis = 3)\n",
        "    conv6 = Conv2D(512, 3, activation = 'relu', padding = 'same', kernel_initializer = 'random_normal')(merge6)\n",
        "    conv6 = Conv2D(512, 3, activation = 'relu', padding = 'same', kernel_initializer = 'random_normal')(conv6)\n",
        "    conv6 = BatchNormalization()(conv6)\n",
        "\n",
        "    up7 = Conv2D(256, 2, activation = 'relu', padding = 'same', kernel_initializer = 'random_normal')(UpSampling2D(size = (2,2))(conv6))\n",
        "    merge7 = concatenate([conv3,up7], axis = 3)\n",
        "    conv7 = Conv2D(256, 3, activation = 'relu', padding = 'same', kernel_initializer = 'random_normal')(merge7)\n",
        "    conv7 = Conv2D(256, 3, activation = 'relu', padding = 'same', kernel_initializer = 'random_normal')(conv7)\n",
        "    conv7 = BatchNormalization()(conv7)\n",
        "\n",
        "    up8 = Conv2D(128, 2, activation = 'relu', padding = 'same', kernel_initializer = 'random_normal')(UpSampling2D(size = (2,2))(conv7))\n",
        "    merge8 = concatenate([conv2,up8], axis = 3)\n",
        "    conv8 = Conv2D(128, 3, activation = 'relu', padding = 'same', kernel_initializer = 'random_normal')(merge8)\n",
        "    conv8 = Conv2D(128, 3, activation = 'relu', padding = 'same', kernel_initializer = 'random_normal')(conv8)\n",
        "    conv8 = BatchNormalization()(conv8)\n",
        "\n",
        "    up9 = Conv2D(64, 2, activation = 'relu', padding = 'same', kernel_initializer = 'random_normal')(UpSampling2D(size = (2,2))(conv8))\n",
        "    merge9 = concatenate([conv1,up9], axis = 3)\n",
        "    conv9 = Conv2D(64, 3, activation = 'relu', padding = 'same', kernel_initializer = 'random_normal')(merge9)\n",
        "    conv9 = Conv2D(64, 3, activation = 'relu', padding = 'same', kernel_initializer = 'random_normal')(conv9)\n",
        "    conv9 = Conv2D(16, 3, activation = 'relu', padding = 'same', kernel_initializer = 'random_normal')(conv9)\n",
        "    conv9 = BatchNormalization()(conv9)\n",
        "\n",
        "    # Output layer of the U-Net with a softmax activation\n",
        "    conv10 = Conv2D(9, 1, activation = 'softmax')(conv9)\n",
        "\n",
        "    model = Model(inputs = inputs, outputs = conv10)\n",
        "\n",
        "    model.compile(optimizer = Adam(lr = 0.0001), loss = 'categorical_crossentropy', metrics = ['accuracy'])\n",
        "    \n",
        "    model.summary()\n",
        "    \n",
        "    #filelist_modelweights = sorted(glob.glob('*.h5'), key=numericalSort)\n",
        "    \n",
        "    #if 'model_nocropping.h5' in filelist_modelweights:\n",
        "     #   model.load_weights('model_nocropping.h5')\n",
        "    ##model.load_weights(\"model_onehot.h5\")\n",
        "    return model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0696B-PesPNT",
        "outputId": "c1199738-12aa-4abc-e5cc-0405afb10fad"
      },
      "source": [
        "model = unet()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(None, 1024, 1024, 3)\n",
            "Model: \"functional_1\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_1 (InputLayer)            [(None, 1024, 1024,  0                                            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d (Conv2D)                 (None, 1024, 1024, 6 1792        input_1[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_1 (Conv2D)               (None, 1024, 1024, 6 36928       conv2d[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization (BatchNorma (None, 1024, 1024, 6 256         conv2d_1[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d (MaxPooling2D)    (None, 512, 512, 64) 0           batch_normalization[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_2 (Conv2D)               (None, 512, 512, 128 73856       max_pooling2d[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_3 (Conv2D)               (None, 512, 512, 128 147584      conv2d_2[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_1 (BatchNor (None, 512, 512, 128 512         conv2d_3[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d_1 (MaxPooling2D)  (None, 256, 256, 128 0           batch_normalization_1[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_4 (Conv2D)               (None, 256, 256, 256 295168      max_pooling2d_1[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_5 (Conv2D)               (None, 256, 256, 256 590080      conv2d_4[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_2 (BatchNor (None, 256, 256, 256 1024        conv2d_5[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d_2 (MaxPooling2D)  (None, 128, 128, 256 0           batch_normalization_2[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_6 (Conv2D)               (None, 128, 128, 512 1180160     max_pooling2d_2[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_7 (Conv2D)               (None, 128, 128, 512 2359808     conv2d_6[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_3 (BatchNor (None, 128, 128, 512 2048        conv2d_7[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "dropout (Dropout)               (None, 128, 128, 512 0           batch_normalization_3[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d_3 (MaxPooling2D)  (None, 64, 64, 512)  0           dropout[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_8 (Conv2D)               (None, 64, 64, 1024) 4719616     max_pooling2d_3[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_9 (Conv2D)               (None, 64, 64, 1024) 9438208     conv2d_8[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_4 (BatchNor (None, 64, 64, 1024) 4096        conv2d_9[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "dropout_1 (Dropout)             (None, 64, 64, 1024) 0           batch_normalization_4[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "up_sampling2d (UpSampling2D)    (None, 128, 128, 102 0           dropout_1[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_10 (Conv2D)              (None, 128, 128, 512 2097664     up_sampling2d[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "concatenate (Concatenate)       (None, 128, 128, 102 0           dropout[0][0]                    \n",
            "                                                                 conv2d_10[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_11 (Conv2D)              (None, 128, 128, 512 4719104     concatenate[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_12 (Conv2D)              (None, 128, 128, 512 2359808     conv2d_11[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_5 (BatchNor (None, 128, 128, 512 2048        conv2d_12[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "up_sampling2d_1 (UpSampling2D)  (None, 256, 256, 512 0           batch_normalization_5[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_13 (Conv2D)              (None, 256, 256, 256 524544      up_sampling2d_1[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_1 (Concatenate)     (None, 256, 256, 512 0           batch_normalization_2[0][0]      \n",
            "                                                                 conv2d_13[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_14 (Conv2D)              (None, 256, 256, 256 1179904     concatenate_1[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_15 (Conv2D)              (None, 256, 256, 256 590080      conv2d_14[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_6 (BatchNor (None, 256, 256, 256 1024        conv2d_15[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "up_sampling2d_2 (UpSampling2D)  (None, 512, 512, 256 0           batch_normalization_6[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_16 (Conv2D)              (None, 512, 512, 128 131200      up_sampling2d_2[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_2 (Concatenate)     (None, 512, 512, 256 0           batch_normalization_1[0][0]      \n",
            "                                                                 conv2d_16[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_17 (Conv2D)              (None, 512, 512, 128 295040      concatenate_2[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_18 (Conv2D)              (None, 512, 512, 128 147584      conv2d_17[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_7 (BatchNor (None, 512, 512, 128 512         conv2d_18[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "up_sampling2d_3 (UpSampling2D)  (None, 1024, 1024, 1 0           batch_normalization_7[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_19 (Conv2D)              (None, 1024, 1024, 6 32832       up_sampling2d_3[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_3 (Concatenate)     (None, 1024, 1024, 1 0           batch_normalization[0][0]        \n",
            "                                                                 conv2d_19[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_20 (Conv2D)              (None, 1024, 1024, 6 73792       concatenate_3[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_21 (Conv2D)              (None, 1024, 1024, 6 36928       conv2d_20[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_22 (Conv2D)              (None, 1024, 1024, 1 9232        conv2d_21[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_8 (BatchNor (None, 1024, 1024, 1 64          conv2d_22[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_23 (Conv2D)              (None, 1024, 1024, 9 153         batch_normalization_8[0][0]      \n",
            "==================================================================================================\n",
            "Total params: 31,052,649\n",
            "Trainable params: 31,046,857\n",
            "Non-trainable params: 5,792\n",
            "__________________________________________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Omz8a5KQueEc"
      },
      "source": [
        "color_dict = {0: (0, 0, 0),\n",
        "              1: (0, 125, 0),\n",
        "              2: (150, 80, 0),\n",
        "              3: (255, 255, 0),\n",
        "              4: (100, 100, 100),\n",
        "              5: (0, 255, 0),\n",
        "              6: (0, 0, 150),\n",
        "              7: (150, 150, 255),\n",
        "              8: (255, 255, 255)}\n",
        "\n",
        "def rgb_to_onehot(rgb_arr, color_dict):\n",
        "    num_classes = len(color_dict)\n",
        "    shape = rgb_arr.shape[:2]+(num_classes,)\n",
        "    #print(shape)\n",
        "    arr = np.zeros( shape, dtype=np.int8 )\n",
        "    for i, cls in enumerate(color_dict):\n",
        "        arr[:,:,i] = np.all(rgb_arr.reshape( (-1,3) ) == color_dict[i], axis=1).reshape(shape[:2])\n",
        "    return arr\n",
        "\n",
        "def onehot_to_rgb(onehot, color_dict):\n",
        "    single_layer = np.argmax(onehot, axis=-1)\n",
        "    output = np.zeros( onehot.shape[:2]+(3,) )\n",
        "    for k in color_dict.keys():\n",
        "        output[single_layer==k] = color_dict[k]\n",
        "    return np.uint8(output)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sZzzi8Fhuqip",
        "outputId": "e248a085-9cba-4215-f781-826d550ba784"
      },
      "source": [
        "trainy_hot = []\n",
        "\n",
        "for i in range(trainy.shape[0]):\n",
        "    \n",
        "    hot_img = rgb_to_onehot(trainy[i], color_dict)\n",
        "    trainy_hot.append(hot_img)\n",
        "    \n",
        "trainy_hot = np.asarray(trainy_hot)\n",
        "print(trainy_hot.shape);\n",
        "testy_hot = []\n",
        "\n",
        "for i in range(testy.shape[0]):\n",
        "    \n",
        "    hot_img = rgb_to_onehot(testy[i], color_dict)\n",
        "    \n",
        "    testy_hot.append(hot_img)\n",
        "    \n",
        "testy_hot = np.asarray(testy_hot)\n",
        "print(testy_hot.shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(2925, 128, 128, 9)\n",
            "(225, 128, 128, 9)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5jYCKqU2ujvq",
        "outputId": "0433ec8b-0030-4ee6-eff5-8efb741d10ef"
      },
      "source": [
        "history = model.fit(trainx, trainy_hot, epochs=20, validation_data = (testx, testy_hot),batch_size=64, verbose=1)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/20\n",
            "WARNING:tensorflow:Model was constructed with shape (None, 1024, 1024, 3) for input Tensor(\"input_1:0\", shape=(None, 1024, 1024, 3), dtype=float32), but it was called on an input with incompatible shape (None, 128, 128, 3).\n",
            "WARNING:tensorflow:Model was constructed with shape (None, 1024, 1024, 3) for input Tensor(\"input_1:0\", shape=(None, 1024, 1024, 3), dtype=float32), but it was called on an input with incompatible shape (None, 128, 128, 3).\n",
            " 8/46 [====>.........................] - ETA: 1:02:46 - loss: 0.0000e+00 - accuracy: 0.0720"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}